---
title: "Big Data exercises"
filters: 
  - webr
webr:
  packages: 
    - "dplyr"
    - "jsonlite"
    - "ggplot2"
    - "duckdb"
    - "dbplyr"
editor_options: 
  chunk_output_type: console
---

```{webr-r}

#| context: setup

# Download a dataset
download.file(
  'https://coatless.github.io/raw-data/flights.csv',
  'flights.csv'
)

data_url <- "https://raw.githubusercontent.com/mechtrix/data/main/raw_data/mtcars.duckdb"

download.file(data_url, "mtcars.duckdb")

```

# Getting started

## Your personal R environment

Below you can see R running in the browser. 
It is not as powerful as if we install R on the machine, but it spares us the hassle of setting R up on every of your Computers.
You can type some simple math to try it out!
You can run single lines by pressing `Ctrl` + `Enter`.

```{webr-r}
1+1
```

## loading libraries

As most open source software, R builds upon loading libraries. 
Usually those are found on [CRAN](https://cran.r-project.org/), but in our case they need to be provided.
Let's try loading libraries!

```{webr-r}
library(dplyr)
```

Here we have loaded the [dplyr](https://dplyr.tidyverse.org/) package, which is used for data manipulation.
It is part of the much bigger [tidyverse](https://www.tidyverse.org/).
Since the packages always have to be installed, we will not use the more extensive command `library(tidyverse)`.
This would trigger to install a lot of packages.
If you want to do this on your own machine, please do so

# Data Sources

For BigData we need - Data.
There are many sources out there, we will start working with a couple of them.

## data provided by R

You can simply use data that is natively provided by R.
A famous example is the titanic data set.
Do this using the `data()` command as provided below

```{webr-r}

data("Titanic")

```

There is not a lot that happened, because we do not use an IDE.
An IDE like RStudio would acutally display the variables.
This is a trade-off we have to live with the convinienct of not setting up R, but of course, there are ways around it.
Below are a couple of ways to display data:
- the `print`command is the most verbose way to output data
- the `head` command prints only the first couple of lines (can be specified using `head(object, n = X`)
- the `glimpse` command is very convenient, but needs the `dplyr` package to be loaded or referenced (with `::` as shown below)
- the `str` command give the structure of the object, so it provides a meta view of the variable. This is convenient if you have some unexpected output.

```{webr-r}
print(Titanic)
```


```{webr-r}
head(Titanic)
```


```{webr-r}
dplyr::glimpse(Titanic)
```


```{webr-r}
str(Titanic)
```


## csv

Reading a csv is fairly simple, we just need the file path.
Lucky for you this has been prepared, the file was already downloaded to the Virtual File System (VFS) that webR uses.
Classically, we can use the `read.csv()` function from baseR.
It is not as convenient, but you do not need to install or download any package to work with it.
Check out the variable content using the commands above!

```{webr-r}
flights_data_base <-  read.csv("flights.csv")
```

In the `tidyverse` we also have the [readr](https://readr.tidyverse.org/) package. 
It give more flexibility, for example specifiying columns.
We do not need to care about that now, but it is good to know.

```{webr-r}
library(readr)
flights_data_readr <-  read_csv("flights.csv")

```

But we can also explore the VFS a little by using the `getwd()` and the `list.files()` command.
There you can see the `flights.csv` file that we read in before!
When you output the complete VFS - what do you notice?

```{webr-r}
getwd()

list.files()

list.files('/', full = TRUE, recursive = TRUE)

```

## API

Below you can try to get data from an API.
This is not yet possible using webR for technical and security reasons. 
In theory, it would go like this:

This is the Give Food API at [givefood.org.uk](https://www.givefood.org.uk/api/2/docs/) and shall give us a brief introduction on how to work with API's.
We need two packages: [httr](https://CRAN.R-project.org/package=httr) and [jsonlite](https://CRAN.R-project.org/package=jsonlite).
We are pulling data from a data source that does not need a key [foodbank](https://www.givefood.org.uk/api/2/docs/).

```{r}

library(httr)
library(jsonlite)

foodbank <- httr::GET("https://www.givefood.org.uk/api/2/foodbanks/")

foodbankcontent <- httr::content(foodbank, as = "text")

foodbankJSON <- jsonlite::fromJSON(foodbankcontent)

```

```
Response [https://www.givefood.org.uk/api/2/foodbanks/]
  Date: 2024-10-05 07:50
  Status: 200
  Content-Type: application/json
  Size: 1.28 MB
[
  {
    "name": "Lapford Food Bank",
    "alt_name": null,
    "slug": "lapford",
    "phone": "0136383788",
    "secondary_phone": null,
    "email": "foodbank@lapfordcc.org.uk",
    "address": "Victory Hall\r\nLapford\r\nDevon\r\nEX17 6PZ",
    "postcode": "EX17 6PZ",
...
```

But we can "fake" an API call, just to be able to play around a little with json files.
For this we will download the data that is provided by the API as a csv and re-read it into R.

```{webr-r}
library(jsonlite)

data_url <- "https://raw.githubusercontent.com/mechtrix/data/main/raw_data/foodbank"

download.file(data_url, "foodbank")

foodbankRAW <- readLines("foodbank")

foodbankJSON <- jsonlite::fromJSON(foodbankRAW)

dplyr::glimpse(foodbankJSON)

```

Ok, so now we have data, but what can we do with it?
Below is some code where we count the foodbanks according to region in the UK.

```{webr-r}
cnt_foodbank <- foodbankJSON |> 
  count(country)
```

We then add a ordered barplot so show the counts.
Piece o' cake!

```{webr-r}
cnt_foodbank |> 
  ggplot(
    aes(
      x = reorder(country,-n),
      y = n
    )
  )+
  geom_col()+
  labs(
    title = "Count of foddbanks in the UK per region",
    x = "region",
    y = "count"
  )

```

## Databases

As with API's a *real* connection to a remote database is right now not feasible using webR.
But we can use *duckDB* which is a fast in-process analytical database.
It has one more advantage: It is locally hosted, which means it is a physical file on your machine.
We also use [dbplyr](https://dbplyr.tidyverse.org/) which is a database backend that uses the same or similar logic as *dplyr* for data manipulation with remote data sources.

```{webr-r}
library(duckdb)
library(dbplyr)

ddb_con <- dbConnect(duckdb(), dbdir = "mtcars.duckdb", read_only = FALSE)

mtcars <- tbl(ddb_con,"mtcars_table") |> collect()

```

So did it work? 
You can query the object using the same commands as described above.
Another way is of course to plot it, but that is hard when we do not know what variables are in the dataset.
Sometimes in those cases, the R base plotting is an excellent way of doing some quick E(xplorative)D(ata)A(nalysis)

```{webr}

plot(mtcars)

```

