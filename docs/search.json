[
  {
    "objectID": "Lecture_exercises.html#your-personal-r-environment",
    "href": "Lecture_exercises.html#your-personal-r-environment",
    "title": "Big Data exercises",
    "section": "Your personal R environment",
    "text": "Your personal R environment\nBelow you can see R running in the browser. It is not as powerful as if we install R on the machine, but it spares us the hassle of setting R up on every of your Computers. You can type some simple math to try it out! You can run single lines by pressing Ctrl + Enter.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lecture_exercises.html#loading-libraries",
    "href": "Lecture_exercises.html#loading-libraries",
    "title": "Big Data exercises",
    "section": "loading libraries",
    "text": "loading libraries\nAs most open source software, R builds upon loading libraries. Usually those are found on CRAN, but in our case they need to be provided. Let’s try loading libraries!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere we have loaded the dplyr package, which is used for data manipulation. It is part of the much bigger tidyverse. Since the packages always have to be installed, we will not use the more extensive command library(tidyverse). This would trigger to install a lot of packages. If you want to do this on your own machine, please do so"
  },
  {
    "objectID": "Lecture_exercises.html#data-provided-by-r",
    "href": "Lecture_exercises.html#data-provided-by-r",
    "title": "Big Data exercises",
    "section": "data provided by R",
    "text": "data provided by R\nYou can simply use data that is natively provided by R. A famous example is the titanic data set. Do this using the data() command as provided below\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThere is not a lot that happened, because we do not use an IDE. An IDE like RStudio would acutally display the variables. This is a trade-off we have to live with the convinienct of not setting up R, but of course, there are ways around it. Below are a couple of ways to display data: - the printcommand is the most verbose way to output data - the head command prints only the first couple of lines (can be specified using head(object, n = X) - the glimpse command is very convenient, but needs the dplyr package to be loaded or referenced (with :: as shown below) - the str command give the structure of the object, so it provides a meta view of the variable. This is convenient if you have some unexpected output.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lecture_exercises.html#csv",
    "href": "Lecture_exercises.html#csv",
    "title": "Big Data exercises",
    "section": "csv",
    "text": "csv\nReading a csv is fairly simple, we just need the file path. Lucky for you this has been prepared, the file was already downloaded to the Virtual File System (VFS) that webR uses. Classically, we can use the read.csv() function from baseR. It is not as convenient, but you do not need to install or download any package to work with it. Check out the variable content using the commands above!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn the tidyverse we also have the readr package. It give more flexibility, for example specifiying columns. We do not need to care about that now, but it is good to know.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBut we can also explore the VFS a little by using the getwd() and the list.files() command. There you can see the flights.csv file that we read in before! When you output the complete VFS - what do you notice?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lecture_exercises.html#api",
    "href": "Lecture_exercises.html#api",
    "title": "Big Data exercises",
    "section": "API",
    "text": "API\nBelow you can try to get data from an API. This is not yet possible using webR for technical and security reasons. In theory, it would go like this:\nThis is the Give Food API at givefood.org.uk and shall give us a brief introduction on how to work with API’s. We need two packages: httr and jsonlite. We are pulling data from a data source that does not need a key foodbank.\n\nlibrary(httr)\nlibrary(jsonlite)\n\nfoodbank &lt;- httr::GET(\"https://www.givefood.org.uk/api/2/foodbanks/\")\n\nfoodbankcontent &lt;- httr::content(foodbank, as = \"text\")\n\nfoodbankJSON &lt;- jsonlite::fromJSON(foodbankcontent)\n\nResponse [https://www.givefood.org.uk/api/2/foodbanks/]\n  Date: 2024-10-05 07:50\n  Status: 200\n  Content-Type: application/json\n  Size: 1.28 MB\n[\n  {\n    \"name\": \"Lapford Food Bank\",\n    \"alt_name\": null,\n    \"slug\": \"lapford\",\n    \"phone\": \"0136383788\",\n    \"secondary_phone\": null,\n    \"email\": \"foodbank@lapfordcc.org.uk\",\n    \"address\": \"Victory Hall\\r\\nLapford\\r\\nDevon\\r\\nEX17 6PZ\",\n    \"postcode\": \"EX17 6PZ\",\n...\nBut we can “fake” an API call, just to be able to play around a little with json files. For this we will download the data that is provided by the API as a csv and re-read it into R.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOk, so now we have data, but what can we do with it? Below is some code where we count the foodbanks according to region in the UK.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe then add a ordered barplot so show the counts. Piece o’ cake!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lecture_exercises.html#databases",
    "href": "Lecture_exercises.html#databases",
    "title": "Big Data exercises",
    "section": "Databases",
    "text": "Databases\nAs with API’s a real connection to a remote database is right now not feasible using webR. But we can use duckDB which is a fast in-process analytical database. It has one more advantage: It is locally hosted, which means it is a physical file on your machine. We also use dbplyr which is a database backend that uses the same or similar logic as dplyr for data manipulation with remote data sources.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSo did it work? You can query the object using the same commands as described above. Another way is of course to plot it, but that is hard when we do not know what variables are in the dataset. Sometimes in those cases, the R base plotting is an excellent way of doing some quick E(xplorative)D(ata)A(nalysis)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lecture_exercises.html#web-scraping",
    "href": "Lecture_exercises.html#web-scraping",
    "title": "Big Data exercises",
    "section": "Web scraping",
    "text": "Web scraping\nIn this example we will scrape the F1 driver data from wikipedia, that is online here. The large table contains a lot of data that we want to download. Again, we can not access the data from webR, that why we need to fake it a little, but the general idea on how to access a page online can be seen below.\n\nlibrary(rvest)\nlink &lt;- \"https://en.wikipedia.org/wiki/List_of_Formula_One_drivers\"\n\npage &lt;- read_html(link)\n\nWe take it interactively from here. First, we read in the html file. Above this, you can see how that would work using an url. The file has been downloaded to the VFS, but we can use the same command!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNext, we need to find the right table. Navigate to wikipedia page and look for it. The easiest way to do this, is by right-clicking on the page and choosing inspect. You should see something like this.\n\nThe table is in an table element with the sortable attribute. The rvest package allow for functions that are prepared for this, so we just need to convert the raw page. You may have notices the clean_names() function. This comes from the janitor package, which contains very useful functions for data cleaning. It has been uploaded to your webR already, but check out the github link. Try to alter the code to see the effect of the packagel, you have all the tools available.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNext, we are going to do some data cleaning. We only want to keep certain columns. To achieve this, we use the select() function from dplyr.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAlso, please check out the last row of the dataframe. It appears that this is no data but an explanation of the columns. This would prevent using the data out-of-the-box. But we do not need it anyway, so we get rid of it. Check out the nrow() command by typing ?nrow to see what it does.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn the next step, we need to check out the column drivers_championship. Apparently, in the table are the number of championships the drivers one, but also the years. We are (for now) only interested in the number of won championships, so we get rid of the years information by simply extracting the first character using the substr() function. This is achieved by also using the mutate() command provided by dplyr, you can find more detailed references here.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe next step is there for safety reasons. We make sure with the parse_number() function from the readr package, that all numbers in the columns of interest are actual numbers.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis was a step by step intro, you could also use one long chain of command as outlined below.\n\ndrivers_F1 &lt;- drivers_F1 |&gt; \n  select(\n    driver_name,\n    nationality,\n    seasons_competed,\n    drivers_championships,\n    pole_positions,\n    race_wins,\n    podiums\n  ) |&gt; \n  slice_head(\n    n = nrow(drivers_F1)-1\n  ) |&gt; \n  mutate(\n    drivers_championships = parse_number(substr(drivers_championships,start = 1, stop = 1)),\n    race_wins = parse_number(race_wins),\n    pole_positions = parse_number(pole_positions)\n  )\n\nSo, what now? We can look into how many championships by nation have been won. For this, we first group_by() nation, and then we summarise() the sum of all drivers_championships.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe output is… nothing. We need to look into the created object.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBut the order is alphabetically, we want to see the top nations!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOh no, wrong again, we want to have it descending.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOk, and who is the driver with the most won championships?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNext thing we want to know is, if there is a relationship between number of pole_positions and the number of championships that have been won by a driver (drivers_championsips).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSo what happens in the code block? First we take the dataframe and filter it, so only driver_championships greater than 1 are retained. After that, we pipe it into ggplot2, a plotting system that is based on the Grammar of Graphics. Onto the x-axis we map the number of pole_positions and on the y-axis we map the number of driver_championships. This we plot with a geom_point(), so we tell the function to use points to represent the data. The position = jitter jitters the points and prevents overplotting. The labs() function assigns nice labels to the axis. The geom_smooth() function maps a linear regression line (including the standard error in light gray). In the end we can give the plot a nice theme with theme_minimal()."
  }
]